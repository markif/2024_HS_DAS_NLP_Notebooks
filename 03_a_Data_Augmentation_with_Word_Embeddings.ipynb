{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"400\" src=\"https://www.fhnw.ch/de/++theme++web16theme/assets/media/img/fachhochschule-nordwestschweiz-fhnw-logo.svg\" alt=\"FHNW Logo\">\n",
    "\n",
    "\n",
    "# Data Augmentation with Word Embeddings\n",
    "\n",
    "by Fabian Märki\n",
    "\n",
    "## Summary\n",
    "The aim of this notebook is to show how word embeddings can be used for data augmentation in nlp (similar to [image augmentation](https://github.com/aleju/imgaug)). Data augmentation referes to techniques used to increase the amount of data by adding slightly modified copies of already existing data. It acts as a regularizer and helps to reduce [overfitting](https://en.wikipedia.org/wiki/Overfitting) when training a machine learning model (and thus can improve the model performance). It is closely related to [oversampling](https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis) in data analysis.\n",
    "\n",
    "A simple technique to augment a text (i.e. generate a new text from an existing text with (hopefully) the same meaning) is to replace a selected word (or words) with a synonym. One possible *snonym provider* are word embeddings. More advanced nlp data augmentation techniques include *backtranslation* (e.g. translate text to english and back to german), text summarization, text generation etc.\n",
    "\n",
    "### Sources\n",
    "- [Data Augmentation in NLP: Best Practices](https://neptune.ai/blog/data-augmentation-nlp)\n",
    "- [Data Augmentation in NLP: Introduction to Text Augmentation](https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28)\n",
    "- [Data Augmentation Library for Text](https://towardsdatascience.com/data-augmentation-library-for-text-9661736b13ff)\n",
    "\n",
    "### Libraries\n",
    "- [EDA](https://github.com/jasonwei20/eda_nlp): Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks\n",
    "- [Snorkel for Data Augmentation](https://www.snorkel.org/use-cases/02-spam-data-augmentation-tutorial) (Snorkel can be useful for much more!)\n",
    "\n",
    "This notebook contains assigments: <font color='red'>Questions are written in red.</font>\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/markif/2024_HS_DAS_NLP_Notebooks/blob/master/03_a_Data_Augmentation_with_Word_Embeddings.ipynb\">\n",
    "  <img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install 'fhnw-nlp-utils>=0.8.0,<0.9.0'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS name: posix\n",
      "Platform name: Linux\n",
      "Platform release: 5.15.0-46-generic\n",
      "Python version: 3.6.9\n",
      "CPU cores: 6\n",
      "RAM: 31.12GB total and 17.29GB available\n",
      "Tensorflow version: 2.5.1\n",
      "GPU is available\n",
      "GPU is a NVIDIA GeForce RTX 2070 with Max-Q Design with 8192MiB\n"
     ]
    }
   ],
   "source": [
    "from fhnw.nlp.utils.system import set_log_level\n",
    "from fhnw.nlp.utils.system import system_info\n",
    "\n",
    "set_log_level()\n",
    "print(system_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word similarities and anologies with fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install fasttext\n",
    "\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "from fhnw.nlp.utils.colab import runs_on_colab\n",
    "\n",
    "if runs_on_colab():\n",
    "    from fhnw.nlp.utils.storage import download\n",
    "    # colab as problems handling such large files\n",
    "    model_name = \"cc.de.50.bin\"\n",
    "    download(\"https://drive.switch.ch/index.php/s/fncH84BgISMlT3v/download\", model_name)\n",
    "else:\n",
    "    model_name = \"cc.de.300.bin\"\n",
    "    fasttext.util.download_model('de', if_exists='ignore')\n",
    "    \n",
    "ft = fasttext.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8161019086837769, 'Hausarzt'),\n",
       " (0.7625795602798462, 'Kinderarzt'),\n",
       " (0.7411035299301147, 'Ärztin'),\n",
       " (0.738987147808075, 'Augenarzt'),\n",
       " (0.7332271337509155, 'Lungenarzt'),\n",
       " (0.7182382941246033, 'Frauenarzt'),\n",
       " (0.7172082662582397, 'Arztin'),\n",
       " (0.7090520858764648, 'Psychiater'),\n",
       " (0.7051564455032349, 'Zahnarzt'),\n",
       " (0.70427405834198, 'Mediziner'),\n",
       " (0.7000358700752258, 'Röntgenarzt'),\n",
       " (0.6979174613952637, 'Tierarzt'),\n",
       " (0.6966368556022644, 'arzt'),\n",
       " (0.6895619034767151, 'Familienarzt'),\n",
       " (0.687816858291626, 'Chirurg'),\n",
       " (0.6830509305000305, 'Vertretungsarzt'),\n",
       " (0.6816859245300293, 'Neurologe'),\n",
       " (0.680378258228302, 'HNO-Arzt'),\n",
       " (0.6794061660766602, 'Allgemeinmediziner'),\n",
       " (0.6781229376792908, 'Krankenhausarzt')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.get_nearest_neighbors(\"Arzt\", k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7587202191352844, 'Königs'),\n",
       " (0.7204199433326721, 'Könige'),\n",
       " (0.7051979899406433, 'Kaiser'),\n",
       " (0.677097499370575, 'Königin'),\n",
       " (0.6656137704849243, 'Prinz'),\n",
       " (0.6584029793739319, 'Königen'),\n",
       " (0.6460000872612, 'Herrscher'),\n",
       " (0.6457017660140991, 'Exkönig'),\n",
       " (0.6453478932380676, 'Herzog'),\n",
       " (0.643559992313385, 'Kronprinz'),\n",
       " (0.6374893188476562, 'Prinzen'),\n",
       " (0.6359966397285461, 'Königssohn'),\n",
       " (0.632456362247467, 'Oberkönig'),\n",
       " (0.6273627281188965, 'Fürst'),\n",
       " (0.6244688630104065, 'Marionettenkönig'),\n",
       " (0.6177127957344055, 'Kindkönig'),\n",
       " (0.6165410280227661, 'könig'),\n",
       " (0.6133463978767395, 'Ex-König'),\n",
       " (0.610389232635498, 'Vize-König'),\n",
       " (0.6092323660850525, 'Sachsenkönig')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.get_nearest_neighbors(\"König\", k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6669625639915466, 'Königin'),\n",
       " (0.6069499254226685, 'Königs'),\n",
       " (0.5830625891685486, 'Elisabeth'),\n",
       " (0.5826849937438965, 'Prinzessin'),\n",
       " (0.5708263516426086, 'Beatrix')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# König - Mann + Frau = ?\n",
    "# König is to Mann what ? is to Frau\n",
    "ft.get_analogies(\"König\", \"Mann\", \"Frau\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6908500790596008, 'Berlin'),\n",
       " (0.6577669382095337, 'Köln'),\n",
       " (0.6426689028739929, 'München'),\n",
       " (0.6407095789909363, 'Hamburg'),\n",
       " (0.6280649304389954, 'Frankfurt')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bern - Schweiz + Deutschland = ?\n",
    "# Bern is to Schweiz what ? is to Deutschland\n",
    "ft.get_analogies(\"Bern\", \"Schweiz\", \"Deutschland\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6156734824180603, 'Merkel'),\n",
       " (0.5905285477638245, 'Gauck'),\n",
       " (0.5554210543632507, 'Kanzlerin'),\n",
       " (0.5380834937095642, 'Westerwelle'),\n",
       " (0.5376471281051636, 'Bundeskanzlerin')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obama - USA + Deutschland = ?\n",
    "# Obama is to USA what ? is to Deutschland\n",
    "ft.get_analogies(\"Obama\", \"USA\", \"Deutschland\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.30943680e-02,  1.31165683e-01, -3.24210897e-02, -1.80250704e-02,\n",
       "        2.38739066e-02, -4.41337973e-02, -6.20340370e-02, -8.23560171e-03,\n",
       "        1.73524451e-02, -3.84017229e-02,  1.07646901e-02,  4.14406508e-02,\n",
       "       -3.67401876e-02, -5.90456091e-03, -4.32579815e-02,  5.14640380e-03,\n",
       "        6.35619089e-02, -8.11023265e-02, -6.33341633e-03, -6.03447482e-03,\n",
       "       -3.18285897e-02, -4.17994037e-02, -1.36623690e-02,  2.55087372e-02,\n",
       "       -9.64077748e-03,  7.87197277e-02,  7.53838345e-02,  3.98097150e-02,\n",
       "       -1.94040798e-02,  4.53237370e-02, -7.12714046e-02,  5.16645126e-02,\n",
       "       -7.53148273e-02,  9.91312880e-03, -2.51716301e-02, -4.70333844e-02,\n",
       "        7.94803165e-03,  9.97908413e-03,  4.16203849e-02, -5.36185205e-02,\n",
       "        9.62086581e-03, -1.10661499e-01, -4.43915427e-02, -1.02308542e-01,\n",
       "       -3.96078527e-02,  1.55621711e-02,  4.00714986e-02, -3.04852035e-02,\n",
       "       -2.95244269e-02,  1.11928508e-01,  4.01469804e-02, -5.12187593e-02,\n",
       "        8.58442485e-02,  6.77174404e-02, -2.69524753e-06, -1.37215247e-02,\n",
       "        1.29279783e-02,  4.67925854e-02,  2.78614159e-03,  8.94122105e-03,\n",
       "       -2.11151578e-02,  4.70689572e-02,  3.66831087e-02,  8.32787976e-02,\n",
       "        4.28060666e-02, -6.01997748e-02,  7.62142390e-02, -8.40884820e-02,\n",
       "        5.90913696e-03,  3.27849984e-02,  4.93191853e-02,  4.83593903e-03,\n",
       "       -4.97446880e-02, -9.02145170e-03,  2.52900105e-02, -2.95283087e-02,\n",
       "       -1.46812182e-02,  5.22170290e-02, -2.84239352e-02, -5.74440621e-02,\n",
       "       -9.65072587e-02, -3.87015976e-02, -4.16401308e-04,  2.86442228e-03,\n",
       "       -1.25618637e-01,  1.12892866e-01, -8.48950446e-03,  2.26828493e-02,\n",
       "       -5.00763431e-02,  4.73924465e-02,  1.07292101e-01,  1.16712116e-01,\n",
       "       -1.55865587e-03, -1.86111629e-02,  3.98631170e-02, -5.08010760e-02,\n",
       "        7.47022852e-02,  3.17576677e-02, -8.63222033e-02,  4.77292947e-03,\n",
       "        1.55422799e-02,  6.56564608e-02, -1.11869955e-03,  7.45940655e-02,\n",
       "       -4.88979109e-02,  2.39679851e-02, -1.96090974e-02,  1.65505484e-01,\n",
       "        8.38467032e-02, -7.18531609e-02, -3.69921587e-02,  1.25443731e-02,\n",
       "       -5.52370660e-02, -7.76468664e-02,  4.15698439e-02, -4.77239862e-02,\n",
       "       -4.71943952e-02,  8.13779049e-03,  6.24602959e-02, -4.67435308e-02,\n",
       "       -4.70592547e-03,  3.98825388e-04, -1.66342407e-02,  6.59047514e-02,\n",
       "        2.76609100e-02, -1.28336474e-02, -3.94739769e-02, -2.28241328e-02,\n",
       "        6.41087592e-02, -1.13891259e-01, -2.50015050e-01,  8.64657760e-02,\n",
       "       -7.12355748e-02,  3.56778204e-02,  2.70133018e-02,  7.00510573e-03,\n",
       "        1.27680600e-01,  5.27534112e-02,  5.01578785e-02, -5.75881172e-03,\n",
       "        9.20885503e-02, -8.69482309e-02,  1.93780050e-01, -4.47761491e-02,\n",
       "       -3.19637880e-02,  8.55035242e-03,  1.56363938e-03,  1.28969043e-01,\n",
       "        1.83512010e-02,  5.54736285e-03,  8.00277516e-02,  8.31730440e-02,\n",
       "       -9.99098420e-02,  5.99890426e-02,  3.27624269e-02,  8.29297379e-02,\n",
       "        2.12238580e-02, -6.44077174e-03, -4.46938910e-02, -1.17424414e-01,\n",
       "       -4.57191654e-02, -6.20640116e-03,  2.88207084e-02,  7.27414340e-02,\n",
       "       -7.71645755e-02,  5.59985712e-02, -2.45590378e-02,  2.28982940e-02,\n",
       "       -4.81002815e-02, -1.09219246e-01,  1.18009523e-02,  8.83735865e-02,\n",
       "        1.35436021e-02, -1.88354459e-02,  1.52138900e-02,  4.15172316e-02,\n",
       "       -3.00406702e-02,  6.81634340e-03, -4.04456109e-02,  3.92020121e-02,\n",
       "        1.94649752e-02,  2.23491192e-02,  4.31762263e-03, -8.28709230e-02,\n",
       "       -5.16354628e-02, -8.12247023e-02,  1.45469420e-02, -1.77950766e-02,\n",
       "        6.11659586e-02,  4.25327495e-02,  6.37240037e-02,  1.69447325e-02,\n",
       "       -4.91584800e-02, -2.67852936e-02,  1.63256675e-02,  4.09650430e-02,\n",
       "        2.02879496e-03,  4.67583165e-02, -2.88719349e-02,  4.17018123e-03,\n",
       "        1.44057751e-01, -4.81377840e-02, -2.63977777e-02, -1.31170033e-02,\n",
       "        6.92565218e-02,  6.17269650e-02,  3.84684727e-02, -3.37228440e-02,\n",
       "       -4.87818047e-02,  2.09728442e-03,  6.71329023e-03,  1.25560025e-02,\n",
       "       -3.76239717e-02, -1.69232115e-02, -2.52982937e-02, -4.97837085e-03,\n",
       "       -6.79001957e-02,  4.83082980e-02,  1.18165901e-02, -2.02113949e-02,\n",
       "       -7.35806748e-02,  2.58614942e-02,  3.82406451e-02,  2.66869143e-02,\n",
       "       -2.92026810e-02, -9.77746174e-02, -1.97860282e-02,  1.26615558e-02,\n",
       "        7.32201487e-02,  7.39015043e-02,  7.21561611e-02, -3.35290506e-02,\n",
       "        4.21804748e-02,  2.31385641e-02,  1.61132708e-01,  1.44913390e-01,\n",
       "        2.89417431e-03,  4.92725782e-02,  5.22802919e-02, -9.25498009e-02,\n",
       "        4.21525687e-02, -1.05277538e-01,  9.84363258e-03, -1.74530428e-02,\n",
       "        6.32796437e-04,  3.91244926e-02, -7.16535971e-02, -1.75483078e-02,\n",
       "       -5.64910360e-02, -4.14403118e-02, -4.60786670e-02,  2.58828029e-02,\n",
       "        1.95363425e-02,  4.75399718e-02, -1.08069852e-02,  2.34696679e-02,\n",
       "       -9.47866961e-03, -4.30080965e-02,  7.31031820e-02, -1.32676214e-04,\n",
       "        7.01163858e-02, -1.70637630e-02,  4.63896543e-02, -1.87560506e-02,\n",
       "        5.35228057e-03, -1.13401115e-02,  4.74487022e-02,  5.98782077e-02,\n",
       "        2.35338099e-02,  6.15190677e-02,  9.74555910e-02, -1.79635976e-02,\n",
       "       -1.46389365e-01, -4.94029745e-02, -7.30967671e-02, -2.30979286e-02,\n",
       "        1.17793247e-01, -2.45304089e-02,  3.74812782e-02,  1.31777674e-02,\n",
       "       -1.67860329e-01,  1.61779709e-02, -2.83782557e-03, -9.07482952e-03,\n",
       "       -3.86304688e-03,  3.09380330e-03,  6.73877150e-02, -6.08395860e-02,\n",
       "        2.02251747e-02, -4.64404821e-02,  6.57142326e-03,  1.57152712e-02,\n",
       "        1.66264530e-02,  3.43218111e-02, -2.80166008e-02,  2.56290510e-02,\n",
       "        3.61554511e-02,  1.41077675e-02,  2.35566646e-02,  4.14628685e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the vector\n",
    "ft.get_word_vector(\"König\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a synonym provider using word embeddings (i.e. fasttext)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**TASK: Implement `synonym_provider` using fasttext's [`get_nearest_neighbors`](https://fasttext.cc/docs/en/unsupervised-tutorial.html#nearest-neighbor-queries) function (as shown above) and provide the functionality as described in the function documentation.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_provider(word):\n",
    "    \"\"\"Provides a list of synonyms for the given word\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    word : str\n",
    "        The word to get the synonym\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of synonyms for the given word\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: !!! place your code here !!!\n",
    "    ####################################\n",
    "    # !!! this needs rework !!!\n",
    "    synonyms = [word]\n",
    "\n",
    "    ###################\n",
    "    # TODO: !!! end !!!\n",
    "    \n",
    "    return synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hausarzt',\n",
       " 'Kinderarzt',\n",
       " 'Ärztin',\n",
       " 'Augenarzt',\n",
       " 'Lungenarzt',\n",
       " 'Frauenarzt',\n",
       " 'Arztin',\n",
       " 'Psychiater',\n",
       " 'Zahnarzt',\n",
       " 'Mediziner',\n",
       " 'Röntgenarzt',\n",
       " 'Tierarzt',\n",
       " 'arzt',\n",
       " 'Familienarzt',\n",
       " 'Chirurg',\n",
       " 'Vertretungsarzt',\n",
       " 'Neurologe',\n",
       " 'HNO-Arzt',\n",
       " 'Allgemeinmediziner',\n",
       " 'Krankenhausarzt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_provider(\"Arzt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Question: Why is it a good idea to use fasttext to find synonyms for German words (i.e. why would word2vec not work that well)? Are there alternatives we could use?**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>Your answer...</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "def synonym_replacement(words, unique_words, n, synonym_provider):\n",
    "    \"\"\"Replaces words through synonyms\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    words : list\n",
    "        The word tokens\n",
    "    unique_words : set\n",
    "        The set of unique words\n",
    "    n : int\n",
    "        The number of words to replace\n",
    "    synonym_provider : function\n",
    "        The function to provide a synonym for a specific word\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The new text sequence \n",
    "    \"\"\"\n",
    "    \n",
    "    import random\n",
    "    from random import shuffle\n",
    "        \n",
    "    random_words = list(unique_words)\n",
    "    random.shuffle(random_words)\n",
    "    random_word = random_words[0]\n",
    "    synonyms = synonym_provider(random_word)\n",
    "    #random.shuffle(synonyms)\n",
    "    sentences = []\n",
    "    \n",
    "    for i in range(0, min(n, len(synonyms))):\n",
    "        synonym = synonyms[i]\n",
    "        new_words = [synonym if word == random_word else word for word in words]\n",
    "        sentences.append(' '.join(new_words))\n",
    "\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def augment_text(text, stopwords, synonym_provider, num_aug=8):\n",
    "    \"\"\"The main augmentation function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The text\n",
    "    stopwords : set\n",
    "        The set of stopwords\n",
    "    synonym_provider : function\n",
    "        The function to provide a synonym for a specific word\n",
    "    num_aug : int\n",
    "        The number of generated augmented sentences per original sentence\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        The new generated text sequences \n",
    "    \"\"\"\n",
    "    \n",
    "    from fhnw.nlp.utils.processing import is_iterable\n",
    "\n",
    "    if isinstance(text, str):\n",
    "        from fhnw.nlp.utils.defaults import default_tokenizer\n",
    "        words = default_tokenizer()(text)\n",
    "    elif is_iterable(text):\n",
    "        words = text\n",
    "    else:\n",
    "        raise TypeError(\"Only string or iterable is supported. Received a \"+ str(type(text)))\n",
    "    \n",
    "    unique_words = set([word for word in words if word not in stopwords])\n",
    "    if len(unique_words) == 0:\n",
    "        # stop here\n",
    "        return []\n",
    "        \n",
    "    return synonym_replacement(words, unique_words, num_aug, synonym_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ich bin äußerst unzufrieden mit diesem Arzt',\n",
       " 'ich bin extrem unzufrieden mit diesem Arzt',\n",
       " 'ich bin überaus unzufrieden mit diesem Arzt',\n",
       " 'ich bin außerordentlich unzufrieden mit diesem Arzt',\n",
       " 'ich bin ziemlich unzufrieden mit diesem Arzt']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = set([\"ich\", \"bin\", \"mit\", \"diesem\"])\n",
    "\n",
    "augment_text(\"ich bin sehr unzufrieden mit diesem Arzt\", stopwords, synonym_provider, num_aug=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
